# Core transformers and models
transformers>=4.30.0
accelerate>=0.20.0
diffusers>=0.21.0
safetensors>=0.3.0

# Quantization and optimization
torchao>=0.2.0
gguf>=0.1.0
bitsandbytes>=0.40.0
optimum[onnx,exporters]>=1.13.0

# Advanced Quantization (Post-training & QAT)
auto-gptq>=0.7.0
autoawq>=0.2.0
neural-speed>=2.0.0

# Pruning and Sparsity
sparseml>=1.7.0
wanda-pruning>=1.0.0; python_version >= '3.8'

# Distillation frameworks
sentence-transformers>=2.7.0

# ONNX optimization and conversion
onnx-simplifier>=0.4.33
skl2onnx>=1.16.0

# End-to-end model optimization pipeline
neural-compressor>=3.1.0

# Intel optimization for CPU inference
intel-extension-for-transformers>=1.3.0

# OpenVINO toolkit (model optimization and inference)
openvino>=2024.1.0

# UI and visualization
gradio>=4.0.0
pyyaml>=6.0
requests>=2.31.0

# Framework support
tensorflow-cpu>=2.10.0; sys_platform != 'darwin' or platform_machine != 'arm64'
tensorflow>=2.10.0; sys_platform == 'darwin' and platform_machine == 'arm64'
jax>=0.4.0
jaxlib>=0.4.0

# Additional utilities
numpy>=1.23.0
pillow>=9.0.0
opencv-python>=4.7.0
librosa>=0.10.0
scipy>=1.10.0

# ONNX support (optional, for model export)
onnx>=1.14.0
onnxruntime>=1.16.0

# Quantization tools
llama-cpp-python>=0.2.0; sys_platform == 'linux' or sys_platform == 'darwin'